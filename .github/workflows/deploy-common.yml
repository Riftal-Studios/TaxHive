name: Common Deployment

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
        description: 'Environment name (staging or production)'
      deploy_type:
        required: false
        type: string
        default: 'deploy'
        description: 'Deployment type (deploy or rebuild)'
      image_tag:
        required: true
        type: string
        description: 'Docker image tag to deploy'
      vps_host:
        required: true
        type: string
        description: 'VPS host address'
      vps_user:
        required: true
        type: string
        description: 'VPS username'
      vps_port:
        required: true
        type: string
        description: 'VPS port'

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Set deployment variables
        id: vars
        run: |
          if [ "${{ inputs.environment }}" = "production" ]; then
            echo "deploy_dir=gsthive-production" >> $GITHUB_OUTPUT
            echo "compose_project=gsthive-prod" >> $GITHUB_OUTPUT
            echo "node_env=production" >> $GITHUB_OUTPUT
          else
            echo "deploy_dir=gsthive-staging" >> $GITHUB_OUTPUT
            echo "compose_project=gsthive-staging" >> $GITHUB_OUTPUT
            echo "node_env=staging" >> $GITHUB_OUTPUT
          fi
          
          # Capture environment variables
          echo "postgres_user=${{ vars.POSTGRES_USER }}" >> $GITHUB_OUTPUT
          echo "postgres_db=${{ vars.POSTGRES_DB }}" >> $GITHUB_OUTPUT
          echo "nextauth_url=${{ vars.NEXTAUTH_URL }}" >> $GITHUB_OUTPUT
          
          # Debug: Show what NEXTAUTH_URL is being captured
          echo "DEBUG: NEXTAUTH_URL being captured: ${{ vars.NEXTAUTH_URL }}"
          echo "email_provider=${{ vars.EMAIL_PROVIDER }}" >> $GITHUB_OUTPUT
          echo "email_from=${{ vars.EMAIL_FROM }}" >> $GITHUB_OUTPUT
          echo "aws_ses_region=${{ vars.AWS_SES_REGION }}" >> $GITHUB_OUTPUT
          echo "aws_region=${{ vars.AWS_REGION }}" >> $GITHUB_OUTPUT
          echo "aws_s3_bucket=${{ vars.AWS_S3_BUCKET }}" >> $GITHUB_OUTPUT
          echo "aws_s3_region=${{ vars.AWS_S3_REGION }}" >> $GITHUB_OUTPUT
          echo "aws_s3_endpoint=${{ vars.AWS_S3_ENDPOINT }}" >> $GITHUB_OUTPUT
          echo "aws_s3_force_path_style=${{ vars.AWS_S3_FORCE_PATH_STYLE }}" >> $GITHUB_OUTPUT
          echo "aws_s3_public_read=${{ vars.AWS_S3_PUBLIC_READ }}" >> $GITHUB_OUTPUT

      - name: Create deployment package
        run: |
          mkdir -p deployment
          cp docker/docker-compose.production.yml deployment/docker-compose.yml
          
          # Replace build sections with image references
          export DOCKER_IMAGE="${{ inputs.image_tag }}"
          awk -v image="$DOCKER_IMAGE" '
            /^  app:/ { in_app=1 }
            /^  queue-worker:/ { in_queue_worker=1 }
            /^  cron:/ { in_cron=1 }
            /^  [a-z-]+:/ && !/^  (app|queue-worker|cron):/ { in_app=0; in_queue_worker=0; in_cron=0 }
            
            /^    build:/ {
              if (in_app || in_queue_worker || in_cron) {
                print "    image: " image
                # Skip the build section
                while (getline && /^      /) {}
                # Print the current line if it is not part of build section
                if (!/^      /) print
                next
              }
            }
            { print }
          ' deployment/docker-compose.yml > deployment/docker-compose.yml.tmp
          mv deployment/docker-compose.yml.tmp deployment/docker-compose.yml
          
          tar -czf deployment.tar.gz deployment/

      - name: Copy deployment package to VPS
        uses: appleboy/scp-action@v1.0.0
        with:
          host: ${{ inputs.vps_host }}
          username: ${{ inputs.vps_user }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ inputs.vps_port }}
          source: deployment.tar.gz
          target: /tmp/

      - name: Deploy to VPS
        uses: appleboy/ssh-action@v1.2.2
        with:
          host: ${{ inputs.vps_host }}
          username: ${{ inputs.vps_user }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ inputs.vps_port }}
          script: |
            set -e  # Exit on error
            
            # Extract deployment package to environment directory
            mkdir -p /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}
            cd /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}
            
            # Clean up old deployment files
            rm -rf deployment
            
            # Extract new deployment
            tar -xzf /tmp/deployment.tar.gz
            cp -f deployment/* . || true
            rm -rf deployment
            
            # Set deployment type
            export DEPLOY_TYPE='${{ inputs.deploy_type }}'
            export COMPOSE_PROJECT_NAME='${{ steps.vars.outputs.compose_project }}'
            
            # Create secrets directory
            mkdir -p /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets
            chmod 700 /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets
            
            # Write secrets to files
            echo "${{ secrets.POSTGRES_PASSWORD }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/postgres_password
            echo "${{ secrets.REDIS_PASSWORD }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/redis_password
            echo "${{ secrets.NEXTAUTH_SECRET }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/nextauth_secret
            echo "${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/cloudflare_tunnel_token
            echo "${{ secrets.GITHUB_TOKEN }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/github_token
            echo "${{ secrets.AWS_SES_SMTP_USER }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/aws_ses_smtp_user
            echo "${{ secrets.AWS_SES_SMTP_PASSWORD }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/aws_ses_smtp_password
            echo "${{ secrets.AWS_SES_ACCESS_KEY_ID }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/aws_ses_access_key_id
            echo "${{ secrets.AWS_SES_SECRET_ACCESS_KEY }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/aws_ses_secret_access_key
            echo "${{ secrets.AWS_ACCESS_KEY_ID }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/aws_access_key_id
            echo "${{ secrets.AWS_SECRET_ACCESS_KEY }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/aws_secret_access_key
            echo "${{ secrets.RBI_API_KEY }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/rbi_api_key
            echo "${{ secrets.EXCHANGE_RATE_API_KEY }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/exchange_rate_api_key
            echo "${{ secrets.CRON_SECRET }}" > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/cron_secret
            
            # Set proper permissions on secret files
            chmod 600 /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/*
            
            # Create .env file with all configuration
            cat > /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/.env << EOF
            # Database
            POSTGRES_USER=${{ steps.vars.outputs.postgres_user }}
            POSTGRES_DB=${{ steps.vars.outputs.postgres_db }}
            POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
            
            # Redis
            REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}
            
            # NextAuth
            NEXTAUTH_URL=${{ steps.vars.outputs.nextauth_url }}
            NEXTAUTH_SECRET=${{ secrets.NEXTAUTH_SECRET }}
            
            # Email
            EMAIL_PROVIDER=${{ steps.vars.outputs.email_provider }}
            EMAIL_FROM=${{ steps.vars.outputs.email_from }}
            AWS_SES_SMTP_USER=${{ secrets.AWS_SES_SMTP_USER }}
            AWS_SES_SMTP_PASSWORD=${{ secrets.AWS_SES_SMTP_PASSWORD }}
            AWS_SES_REGION=${{ steps.vars.outputs.aws_ses_region }}
            
            # AWS
            AWS_REGION=${{ steps.vars.outputs.aws_region }}
            AWS_S3_BUCKET=${{ steps.vars.outputs.aws_s3_bucket }}
            AWS_S3_REGION=${{ steps.vars.outputs.aws_s3_region }}
            AWS_S3_ENDPOINT=${{ steps.vars.outputs.aws_s3_endpoint }}
            AWS_S3_FORCE_PATH_STYLE=${{ steps.vars.outputs.aws_s3_force_path_style }}
            AWS_S3_PUBLIC_READ=${{ steps.vars.outputs.aws_s3_public_read }}
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            
            # Other
            NODE_ENV=${{ steps.vars.outputs.node_env }}
            RBI_API_KEY=${{ secrets.RBI_API_KEY }}
            EXCHANGE_RATE_API_KEY=${{ secrets.EXCHANGE_RATE_API_KEY }}
            CRON_SECRET=${{ secrets.CRON_SECRET }}
            EOF
            
            # Set proper permissions on .env file
            chmod 600 /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/.env
            
            # Create environment-specific docker network if it doesn't exist
            docker network create gsthive-${{ inputs.environment }}-network || true
            
            # Login to GitHub Container Registry
            cat /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}/secrets/github_token | docker login ghcr.io -u ${{ github.actor }} --password-stdin
            
            # Pull latest images
            docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env pull
            
            # Create docker-compose.override.yml for Cloudflare tunnel
            cat > docker-compose.override.yml << EOF
            services:
              cloudflared:
                command: ["tunnel", "--no-autoupdate", "run", "--token", "${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}"]
            EOF
            
            # Deploy with docker compose --env-file .env
            export COMPOSE_ENV=${{ inputs.environment }}
            if [ "${{ inputs.deploy_type }}" = "rebuild" ]; then
                echo "Rebuilding all services..."
                docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env down
                docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env up -d --force-recreate
            else
                echo "Standard deployment..."
                docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env up -d
            fi
            
            # Wait for services to be healthy
            echo "Waiting for services to be healthy..."
            sleep 30
            
            # Check container health
            docker compose --env-file .env ps
            
            # Cleanup
            rm -f /tmp/deployment.tar.gz

      - name: Run database migrations
        uses: appleboy/ssh-action@v1.2.2
        with:
          host: ${{ inputs.vps_host }}
          username: ${{ inputs.vps_user }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ inputs.vps_port }}
          script: |
            set -e  # Exit on error
            
            cd /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}
            
            # Build DATABASE_URL for migrations
            POSTGRES_USER="${{ vars.POSTGRES_USER || 'postgres' }}"
            POSTGRES_DB="${{ vars.POSTGRES_DB || 'gsthive' }}"
            POSTGRES_PASSWORD="${{ secrets.POSTGRES_PASSWORD }}"
            DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}"
            
            # Check container status before migrations
            echo "Checking container status..."
            docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env ps
            
            # Check app logs to see why it might be restarting
            echo "Checking app container logs..."
            docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env logs app --tail=50
            
            # Wait for container to be ready
            echo "Waiting for container to be ready..."
            for i in {1..10}; do
              if docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env exec -T app echo "Container is ready"; then
                echo "✅ Container is ready"
                break
              else
                if [ $i -eq 10 ]; then
                  echo "❌ Container failed to become ready after 10 attempts"
                  docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env ps
                  docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env logs app --tail=100
                  exit 1
                fi
                echo "Container not ready yet, attempt $i/10, waiting 5 seconds..."
                sleep 5
              fi
            done
            
            echo "Running database migrations..."
            docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env exec -T -e DATABASE_URL="$DATABASE_URL" app npx prisma migrate deploy
            
            echo "✅ Migrations completed successfully"

      - name: Health check
        uses: appleboy/ssh-action@v1.2.2
        with:
          host: ${{ inputs.vps_host }}
          username: ${{ inputs.vps_user }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ inputs.vps_port }}
          script: |
            set -e  # Exit on error
            
            cd /home/${{ inputs.vps_user }}/${{ steps.vars.outputs.deploy_dir }}
            
            # Check internal health endpoint with retries
            echo "Checking internal health..."
            for i in {1..5}; do
              # Use Node.js to check health endpoint (same as Dockerfile HEALTHCHECK)
              if docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env exec -T app node -e "require('http').get('http://localhost:3000/api/health', (res) => { console.log('Health check status:', res.statusCode); process.exit(res.statusCode === 200 ? 0 : 1) })"; then
                echo "✅ Internal health check passed"
                break
              else
                if [ $i -eq 5 ]; then
                  echo "❌ Internal health check failed after 5 attempts"
                  echo "Container logs:"
                  docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env logs app --tail=50
                  exit 1
                fi
                echo "Health check attempt $i failed, retrying in 10 seconds..."
                sleep 10
              fi
            done
            
            # Check Cloudflare tunnel
            echo "Checking Cloudflare tunnel..."
            docker compose --project-name ${{ steps.vars.outputs.compose_project }} --env-file .env logs cloudflared --tail=20
            
            # External health check (non-blocking)
            sleep 5
            HEALTH_URL="${{ inputs.environment == 'staging' && (vars.STAGING_NEXTAUTH_URL || vars.NEXTAUTH_URL) || vars.NEXTAUTH_URL }}/api/health"
            if curl -f -s "$HEALTH_URL" > /dev/null; then
              echo "✅ External health check passed"
            else
              echo "⚠️  External health check failed (Cloudflare tunnel may still be initializing)"
            fi

      - name: Cleanup old images
        if: success()
        uses: appleboy/ssh-action@v1.2.2
        with:
          host: ${{ inputs.vps_host }}
          username: ${{ inputs.vps_user }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ inputs.vps_port }}
          script: |
            # Clean up Docker (but NEVER prune volumes - that deletes database data!)
            docker system prune -f
            
            # Clean up images older than 7 days (168 hours)
            docker image prune -a -f --filter "until=168h"
            
            # Clean up builder cache
            docker builder prune -f --filter "until=168h"
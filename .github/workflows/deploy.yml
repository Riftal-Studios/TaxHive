name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      deploy_type:
        description: 'Deployment type'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - rebuild

env:
  REGISTRY: ghcr.io

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up environment
        id: env
        run: |
          echo "IMAGE_NAME=$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ steps.env.outputs.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.production
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDTIME=${{ github.event.head_commit.timestamp }}
            VERSION=${{ github.sha }}

  migrate:
    needs: build-and-push
    runs-on: ubuntu-latest
    environment: 
      name: production
      url: https://gsthive.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run database migrations on VPS
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          script: |
            # Set environment variables
            export GITHUB_TOKEN='${{ secrets.GITHUB_TOKEN }}'
            export GITHUB_USER='${{ github.actor }}'
            
            # Login to GitHub Container Registry
            echo $GITHUB_TOKEN | docker login ghcr.io -u $GITHUB_USER --password-stdin
            
            # Pull the latest image
            docker pull ${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]'):latest
            
            # List running containers for debugging
            echo "Current containers:"
            docker ps --format "table {{.Names}}\t{{.Networks}}"
            
            # Get the network that gsthive-postgres is using
            NETWORK_NAME=$(docker inspect gsthive-postgres --format='{{range $k, $v := .NetworkSettings.Networks}}{{$k}}{{end}}' 2>/dev/null || echo "")
            
            if [ -z "$NETWORK_NAME" ]; then
              echo "PostgreSQL container not found. Checking if services need to be started..."
              cd /home/${{ vars.VPS_USER }}/gsthive-production
              
              # Check if docker-compose.yml exists
              if [ -f docker-compose.yml ]; then
                # Just ensure postgres is running, don't recreate
                docker-compose up -d postgres redis --no-recreate
                sleep 5
                
                # Get network again
                NETWORK_NAME=$(docker inspect gsthive-postgres --format='{{range $k, $v := .NetworkSettings.Networks}}{{$k}}{{end}}')
              else
                echo "No docker-compose.yml found in production directory"
                exit 1
              fi
            fi
            
            echo "Using network: $NETWORK_NAME"
            
            # Run migrations in a temporary container connected to the production network
            echo "Running database migrations..."
            docker run --rm \
              --network $NETWORK_NAME \
              -e DATABASE_URL="postgresql://${{ vars.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@gsthive-postgres:5432/${{ vars.POSTGRES_DB }}?schema=public" \
              ${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]'):latest \
              npx prisma migrate deploy
            
            # Check if it failed
            MIGRATION_EXIT_CODE=$?
            if [ $MIGRATION_EXIT_CODE -ne 0 ]; then
              echo "Migrations failed with exit code $MIGRATION_EXIT_CODE"
              
              # Try to check the error and resolve if it's a failed migration
              echo "Attempting to resolve failed migrations..."
              docker run --rm \
                --network $NETWORK_NAME \
                -e DATABASE_URL="postgresql://${{ vars.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@gsthive-postgres:5432/${{ vars.POSTGRES_DB }}?schema=public" \
                --entrypoint /bin/sh \
                ${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]'):latest \
                -c "
                  # Try to resolve each migration that might have failed
                  npx prisma migrate resolve --rolled-back 20250716172554_init 2>/dev/null || true
                  npx prisma migrate resolve --rolled-back 20250723033426_add_onboarding_fields 2>/dev/null || true
                  npx prisma migrate resolve --rolled-back 20250723132410_add_email_history 2>/dev/null || true
                  npx prisma migrate resolve --rolled-back 20250723135037_add_payment_status_to_invoices 2>/dev/null || true
                  npx prisma migrate resolve --rolled-back 20250723164234_gsthive 2>/dev/null || true
                  npx prisma migrate resolve --rolled-back 20250723171450_ree 2>/dev/null || true
                  
                  # Now try to run migrations again
                  echo 'Retrying migrations after resolution...'
                  npx prisma migrate deploy
                "
            fi

  deploy:
    needs: migrate
    runs-on: ubuntu-latest
    environment: 
      name: production
      url: https://gsthive.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create deployment package
        run: |
          mkdir -p deployment
          cp docker/docker-compose.production.yml deployment/docker-compose.yml
          
          # Replace build sections with image references
          # Use environment variable to pass the image name to awk
          export DOCKER_IMAGE_PROD="${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]'):latest"
          awk -v image="$DOCKER_IMAGE_PROD" '
            /^  app:/ { in_app=1 }
            /^  queue-worker:/ { in_queue_worker=1 }
            /^  cron:/ { in_cron=1 }
            /^  [a-z-]+:/ && !/^  (app|queue-worker|cron):/ { in_app=0; in_queue_worker=0; in_cron=0 }
            
            /^    build:/ {
              if (in_app || in_queue_worker || in_cron) {
                print "    image: " image
                # Skip the build section
                while (getline && /^      /) {}
                # Print the current line if it is not part of build section
                if (!/^      /) print
                next
              }
            }
            { print }
          ' deployment/docker-compose.yml > deployment/docker-compose.yml.tmp
          mv deployment/docker-compose.yml.tmp deployment/docker-compose.yml
          
          tar -czf deployment.tar.gz deployment/

      - name: Copy deployment package to VPS
        uses: appleboy/scp-action@v0.1.5
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          source: deployment.tar.gz
          target: /tmp/

      - name: Deploy to VPS
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          script: |
            # Extract deployment package to production directory
            mkdir -p /home/${{ vars.VPS_USER }}/gsthive-production
            cd /home/${{ vars.VPS_USER }}/gsthive-production
            
            # Clean up old deployment files
            rm -rf deployment
            
            # Extract new deployment
            tar -xzf /tmp/deployment.tar.gz
            mv deployment/* .
            rmdir deployment
            
            # Set environment variables for deployment
            export GITHUB_TOKEN='${{ secrets.GITHUB_TOKEN }}'
            export GITHUB_USER='${{ github.actor }}'
            export DEPLOY_TYPE='${{ github.event.inputs.deploy_type || 'deploy' }}'
            export COMPOSE_PROJECT_NAME='gsthive-prod'
            
            # Login to GitHub Container Registry
            echo $GITHUB_TOKEN | docker login ghcr.io -u $GITHUB_USER --password-stdin
            
            # Set all environment variables directly from GitHub secrets
            export POSTGRES_USER='${{ vars.POSTGRES_USER }}'
            export POSTGRES_PASSWORD='${{ secrets.POSTGRES_PASSWORD }}'
            export POSTGRES_DB='${{ vars.POSTGRES_DB }}'
            export DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?schema=public"
            export REDIS_PASSWORD='${{ secrets.REDIS_PASSWORD }}'
            export REDIS_URL="redis://:${REDIS_PASSWORD}@redis:6379"
            export NEXTAUTH_URL='${{ vars.NEXTAUTH_URL }}'
            export NEXTAUTH_SECRET='${{ secrets.NEXTAUTH_SECRET }}'
            export EMAIL_PROVIDER='${{ vars.EMAIL_PROVIDER }}'
            export EMAIL_SERVER='${{ secrets.EMAIL_SERVER }}'
            export EMAIL_FROM='${{ vars.EMAIL_FROM }}'
            export AWS_SES_ACCESS_KEY_ID='${{ secrets.AWS_SES_ACCESS_KEY_ID }}'
            export AWS_SES_SECRET_ACCESS_KEY='${{ secrets.AWS_SES_SECRET_ACCESS_KEY }}'
            export AWS_SES_REGION='${{ vars.AWS_SES_REGION }}'
            export AWS_ACCESS_KEY_ID='${{ secrets.AWS_ACCESS_KEY_ID }}'
            export AWS_SECRET_ACCESS_KEY='${{ secrets.AWS_SECRET_ACCESS_KEY }}'
            export AWS_REGION='${{ vars.AWS_REGION }}'
            export AWS_S3_BUCKET='${{ vars.AWS_S3_BUCKET }}'
            export RBI_API_KEY='${{ secrets.RBI_API_KEY }}'
            export EXCHANGE_RATE_API_KEY='${{ secrets.EXCHANGE_RATE_API_KEY }}'
            export CRON_SECRET='${{ secrets.CRON_SECRET }}'
            export CLOUDFLARE_TUNNEL_TOKEN='${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}'
            export DOCKER_REGISTRY='${{ env.REGISTRY }}'
            export DOCKER_IMAGE_PROD='${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr "[:upper:]" "[:lower:]"):latest'
            
            # Pull latest images
            docker-compose pull
            
            # Deploy based on type
            case "$DEPLOY_TYPE" in
              "rebuild")
                echo "Rebuilding all services..."
                docker-compose down
                docker-compose up -d --force-recreate
                ;;
              *)
                echo "Standard deployment..."
                docker-compose up -d
                ;;
            esac
            
            # Health check
            sleep 5
            if docker-compose exec -T app wget -qO- http://localhost:3000/api/health; then
              echo "Health check passed"
            else
              echo "Health check failed"
              docker-compose logs app
              exit 1
            fi
            
            # Cleanup old images
            docker image prune -f
            
            echo "Deployment completed successfully!"
            
            # Cleanup
            rm -f /tmp/deployment.tar.gz

      - name: Notify deployment status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ job.status }}';
            const emoji = status === 'success' ? '✅' : '❌';
            const message = `${emoji} Deployment to production ${status}`;
            
            // Only create deployment status if we have a deployment ID
            if (context.payload.deployment?.id) {
              try {
                await github.rest.repos.createDeploymentStatus({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  deployment_id: context.payload.deployment.id,
                  state: status === 'success' ? 'success' : 'failure',
                  environment: 'production',
                  description: message
                });
              } catch (error) {
                console.log('Could not create deployment status:', error.message);
              }
            } else {
              console.log('No deployment ID found, skipping status update');
            }
            
            // Always log the result
            console.log(message);

  cleanup:
    needs: deploy
    runs-on: ubuntu-latest
    if: success()
    environment: production
    
    steps:
      - name: Clean up VPS
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          script: |
            # Remove deployment files
            rm -rf /home/${{ vars.VPS_USER }}/deployment
            
            # Clean up Docker
            docker system prune -f
            docker volume prune -f
            
            # Keep only last 3 images
            docker images | grep ghcr.io | tail -n +4 | awk '{print $3}' | xargs -r docker rmi
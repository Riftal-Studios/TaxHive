name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      deploy_type:
        description: 'Deployment type'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - rebuild

env:
  REGISTRY: ghcr.io

jobs:
  validate-secrets:
    runs-on: ubuntu-latest
    name: Validate Secrets and Variables
    environment:
      name: production
      url: https://gsthive.com
    steps:
      - name: Check Required Secrets
        run: |
          echo "üîç Validating required secrets and variables..."
          
          # Required secrets - deployment will fail without these
          REQUIRED_SECRETS=(
            "POSTGRES_USER:${{ vars.POSTGRES_USER }}"
            "POSTGRES_PASSWORD:${{ secrets.POSTGRES_PASSWORD }}"
            "POSTGRES_DB:${{ vars.POSTGRES_DB }}"
            "REDIS_PASSWORD:${{ secrets.REDIS_PASSWORD }}"
            "NEXTAUTH_SECRET:${{ secrets.NEXTAUTH_SECRET }}"
            "CLOUDFLARE_TUNNEL_TOKEN:${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}"
            "VPS_SSH_KEY:${{ secrets.VPS_SSH_KEY }}"
            "GITHUB_TOKEN:${{ secrets.GITHUB_TOKEN }}"
          )
          
          # Required variables
          REQUIRED_VARS=(
            "NEXTAUTH_URL:${{ vars.NEXTAUTH_URL }}"
            "VPS_HOST:${{ vars.VPS_HOST }}"
            "VPS_USER:${{ vars.VPS_USER }}"
            "VPS_PORT:${{ vars.VPS_PORT }}"
            "EMAIL_PROVIDER:${{ vars.EMAIL_PROVIDER }}"
            "EMAIL_FROM:${{ vars.EMAIL_FROM }}"
          )
          
          # Optional secrets - warn if missing but don't fail
          OPTIONAL_SECRETS=(
            "AWS_SES_SMTP_USER:${{ secrets.AWS_SES_SMTP_USER }}"
            "AWS_SES_SMTP_PASSWORD:${{ secrets.AWS_SES_SMTP_PASSWORD }}"
            "AWS_SES_ACCESS_KEY_ID:${{ secrets.AWS_SES_ACCESS_KEY_ID }}"
            "AWS_SES_SECRET_ACCESS_KEY:${{ secrets.AWS_SES_SECRET_ACCESS_KEY }}"
            "AWS_ACCESS_KEY_ID:${{ secrets.AWS_ACCESS_KEY_ID }}"
            "AWS_SECRET_ACCESS_KEY:${{ secrets.AWS_SECRET_ACCESS_KEY }}"
            "EXCHANGE_RATE_API_KEY:${{ secrets.EXCHANGE_RATE_API_KEY }}"
            "CRON_SECRET:${{ secrets.CRON_SECRET }}"
          )
          
          # Optional variables
          OPTIONAL_VARS=(
            "AWS_SES_REGION:${{ vars.AWS_SES_REGION }}"
            "AWS_REGION:${{ vars.AWS_REGION }}"
            "AWS_S3_BUCKET:${{ vars.AWS_S3_BUCKET }}"
          )
          
          # Check required secrets
          MISSING_REQUIRED=()
          echo "‚úÖ Checking required secrets..."
          for secret in "${REQUIRED_SECRETS[@]}"; do
            IFS=':' read -r name value <<< "$secret"
            if [ -z "$value" ]; then
              MISSING_REQUIRED+=("Secret: $name")
              echo "  ‚ùå $name - MISSING"
            else
              echo "  ‚úÖ $name - Set"
            fi
          done
          
          # Check required variables
          echo -e "\n‚úÖ Checking required variables..."
          for var in "${REQUIRED_VARS[@]}"; do
            IFS=':' read -r name value <<< "$var"
            if [ -z "$value" ]; then
              MISSING_REQUIRED+=("Variable: $name")
              echo "  ‚ùå $name - MISSING"
            else
              echo "  ‚úÖ $name - Set"
            fi
          done
          
          # Check optional secrets
          MISSING_OPTIONAL=()
          echo -e "\n‚ö†Ô∏è  Checking optional secrets..."
          for secret in "${OPTIONAL_SECRETS[@]}"; do
            IFS=':' read -r name value <<< "$secret"
            if [ -z "$value" ]; then
              MISSING_OPTIONAL+=("Secret: $name")
              echo "  ‚ö†Ô∏è  $name - Missing (optional)"
            else
              echo "  ‚úÖ $name - Set"
            fi
          done
          
          # Check optional variables
          echo -e "\n‚ö†Ô∏è  Checking optional variables..."
          for var in "${OPTIONAL_VARS[@]}"; do
            IFS=':' read -r name value <<< "$var"
            if [ -z "$value" ]; then
              MISSING_OPTIONAL+=("Variable: $name")
              echo "  ‚ö†Ô∏è  $name - Missing (optional)"
            else
              echo "  ‚úÖ $name - Set"
            fi
          done
          
          # Summary
          echo -e "\nüìã Summary:"
          echo "Required: ${#MISSING_REQUIRED[@]} missing"
          echo "Optional: ${#MISSING_OPTIONAL[@]} missing"
          
          # Print warnings for optional
          if [ ${#MISSING_OPTIONAL[@]} -gt 0 ]; then
            echo -e "\n‚ö†Ô∏è  Warning: The following optional secrets/variables are not set:"
            for item in "${MISSING_OPTIONAL[@]}"; do
              echo "  - $item"
            done
            echo -e "\nThese may affect certain features:"
            echo "  - AWS_* : Email sending via SES, file uploads to S3"
            echo "  - EXCHANGE_RATE_API_KEY : Fallback exchange rate API"
            echo "  - CRON_SECRET : Scheduled job authentication"
          fi
          
          # Fail if required are missing
          if [ ${#MISSING_REQUIRED[@]} -gt 0 ]; then
            echo -e "\n‚ùå Error: The following required secrets/variables are not set:"
            for item in "${MISSING_REQUIRED[@]}"; do
              echo "  - $item"
            done
            echo -e "\nPlease set these in your repository settings:"
            echo "  - Secrets: Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí Secrets"
            echo "  - Variables: Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí Variables"
            exit 1
          fi
          
          echo -e "\n‚úÖ All required secrets and variables are set!"

  build-and-push:
    needs: validate-secrets
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up environment
        id: env
        run: |
          echo "IMAGE_NAME=$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ steps.env.outputs.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.production
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDTIME=${{ github.event.head_commit.timestamp }}
            VERSION=${{ github.sha }}

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    environment: 
      name: production
      url: https://gsthive.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create deployment package
        run: |
          mkdir -p deployment
          cp docker/docker-compose.production.yml deployment/docker-compose.yml
          
          # Replace build sections with image references
          # Use environment variable to pass the image name to awk
          export DOCKER_IMAGE_PROD="${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]'):main-${{ github.sha }}"
          awk -v image="$DOCKER_IMAGE_PROD" '
            /^  app:/ { in_app=1 }
            /^  queue-worker:/ { in_queue_worker=1 }
            /^  cron:/ { in_cron=1 }
            /^  [a-z-]+:/ && !/^  (app|queue-worker|cron):/ { in_app=0; in_queue_worker=0; in_cron=0 }
            
            /^    build:/ {
              if (in_app || in_queue_worker || in_cron) {
                print "    image: " image
                # Skip the build section
                while (getline && /^      /) {}
                # Print the current line if it is not part of build section
                if (!/^      /) print
                next
              }
            }
            { print }
          ' deployment/docker-compose.yml > deployment/docker-compose.yml.tmp
          mv deployment/docker-compose.yml.tmp deployment/docker-compose.yml
          
          tar -czf deployment.tar.gz deployment/

      - name: Copy deployment package to VPS
        uses: appleboy/scp-action@v0.1.5
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          source: deployment.tar.gz
          target: /tmp/

      - name: Deploy to VPS
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          script: |
            # Extract deployment package to production directory
            mkdir -p /home/${{ vars.VPS_USER }}/gsthive-production
            cd /home/${{ vars.VPS_USER }}/gsthive-production
            
            # Clean up old deployment files
            rm -rf deployment
            
            # Extract new deployment
            tar -xzf /tmp/deployment.tar.gz
            cp -f deployment/* . || true
            rm -rf deployment
            
            # Set environment variables for deployment
            export GITHUB_TOKEN='${{ secrets.GITHUB_TOKEN }}'
            export GITHUB_USER='${{ github.actor }}'
            export DEPLOY_TYPE='${{ github.event.inputs.deploy_type || 'deploy' }}'
            export COMPOSE_PROJECT_NAME='gsthive-prod'
            
            # Create docker network if it doesn't exist
            docker network create gsthive-network || true
            
            # Login to GitHub Container Registry
            echo $GITHUB_TOKEN | docker login ghcr.io -u $GITHUB_USER --password-stdin
            
            # Create .env file from secrets (more secure than exporting)
            cat << 'EOF' > .env
            POSTGRES_USER=${{ vars.POSTGRES_USER }}
            POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
            POSTGRES_DB=${{ vars.POSTGRES_DB }}
            REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}
            REDIS_URL=redis://:${{ secrets.REDIS_PASSWORD }}@redis:6379
            NEXTAUTH_URL=${{ vars.NEXTAUTH_URL }}
            NEXTAUTH_SECRET=${{ secrets.NEXTAUTH_SECRET }}
            EMAIL_PROVIDER=${{ vars.EMAIL_PROVIDER }}
            EMAIL_FROM=${{ vars.EMAIL_FROM }}
            AWS_SES_SMTP_USER=${{ secrets.AWS_SES_SMTP_USER }}
            AWS_SES_SMTP_PASSWORD=${{ secrets.AWS_SES_SMTP_PASSWORD }}
            AWS_SES_REGION=${{ vars.AWS_SES_REGION }}
            AWS_SES_ACCESS_KEY_ID=${{ secrets.AWS_SES_ACCESS_KEY_ID }}
            AWS_SES_SECRET_ACCESS_KEY=${{ secrets.AWS_SES_SECRET_ACCESS_KEY }}
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            AWS_REGION=${{ vars.AWS_REGION }}
            AWS_S3_BUCKET=${{ vars.AWS_S3_BUCKET }}
            EXCHANGE_RATE_API_KEY=${{ secrets.EXCHANGE_RATE_API_KEY }}
            CRON_SECRET=${{ secrets.CRON_SECRET }}
            CLOUDFLARE_TUNNEL_TOKEN=${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}
            DOCKER_REGISTRY=${{ env.REGISTRY }}
            DOCKER_IMAGE_PROD=${{ env.REGISTRY }}/$(echo ${{ github.repository }} | tr "[:upper:]" "[:lower:]"):main-${{ github.sha }}
            EOF
            
            # Set permissions on .env file
            chmod 600 .env
            
            # Pull latest images
            docker compose --env-file .env pull
            
            # Deploy based on type
            case "$DEPLOY_TYPE" in
              "rebuild")
                echo "Rebuilding all services..."
                docker compose --env-file .env down
                docker compose --env-file .env up -d --force-recreate
                ;;
              *)
                echo "Standard deployment..."
                docker compose --env-file .env up -d
                ;;
            esac
            
            # Verify all containers are running
            echo "Checking running containers..."
            docker compose --env-file .env ps
            
            # Run database migrations from within the app container
            echo "Running database migrations..."
            docker compose --env-file .env exec -T app npx prisma migrate deploy
            
            # Check cloudflared tunnel status
            echo "Checking Cloudflare tunnel logs..."
            docker compose --env-file .env logs cloudflared | tail -20
            
            # Health check - using the actual production URL through Cloudflare
            sleep 10
            if curl -f -s ${{ vars.NEXTAUTH_URL }}/api/health > /dev/null; then
              echo "Health check passed"
            else
              echo "Health check failed - checking container logs"
              docker compose --env-file .env logs app
              # Don't fail deployment immediately - container might be healthy but Cloudflare tunnel not ready
              echo "Note: Container might be healthy even if external check fails"
            fi
            
            # Cleanup old images
            docker image prune -f
            
            echo "Deployment completed successfully!"
            
            # Cleanup
            rm -f /tmp/deployment.tar.gz

      - name: Notify deployment status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ job.status }}';
            const emoji = status === 'success' ? '‚úÖ' : '‚ùå';
            const message = `${emoji} Deployment to production ${status}`;
            
            // Only create deployment status if we have a deployment ID
            if (context.payload.deployment?.id) {
              try {
                await github.rest.repos.createDeploymentStatus({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  deployment_id: context.payload.deployment.id,
                  state: status === 'success' ? 'success' : 'failure',
                  environment: 'production',
                  description: message
                });
              } catch (error) {
                console.log('Could not create deployment status:', error.message);
              }
            } else {
              console.log('No deployment ID found, skipping status update');
            }
            
            // Always log the result
            console.log(message);

  cleanup:
    needs: deploy
    runs-on: ubuntu-latest
    if: success()
    environment:
      name: production
      url: https://gsthive.com
    
    steps:
      - name: Clean up VPS
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ vars.VPS_HOST }}
          username: ${{ vars.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ vars.VPS_PORT }}
          script: |
            # Remove deployment files
            rm -rf /home/${{ vars.VPS_USER }}/deployment
            
            # Clean up Docker (but NEVER prune volumes - that deletes database data!)
            docker system prune -f
            # docker volume prune -f # DANGEROUS - this deletes database data!
            
            # Clean up images older than 7 days (168 hours)
            docker image prune -a -f --filter "until=168h"
            
            # Clean up builder cache
            docker builder prune -f --filter "until=168h"
services:
  # PostgreSQL Database - Internal only
  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - taxhive-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # NO PORTS EXPOSED

  # Redis for queue/caching - Internal only  
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass "${REDIS_PASSWORD}"
    volumes:
      - redis_data:/data
    networks:
      - taxhive-internal
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    # NO PORTS EXPOSED

  # Next.js Application - Internal only
  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile.production
      target: runner
    restart: unless-stopped
    # IMPORTANT: The application code must be updated to read secrets from files.
    # Secrets are available at /run/secrets/<secret_name>.
    # Example in Node.js:
    # const nextAuthSecret = fs.readFileSync('/run/secrets/nextauth_secret', 'utf8').trim();
    # const postgresPassword = fs.readFileSync('/run/secrets/postgres_password', 'utf8').trim();
    # Then construct DATABASE_URL dynamically in the application.
    environment:
      # All configuration from .env file
      NODE_ENV: ${NODE_ENV}
      NEXTAUTH_URL: ${NEXTAUTH_URL}
      NEXTAUTH_SECRET: ${NEXTAUTH_SECRET}
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      EMAIL_PROVIDER: ${EMAIL_PROVIDER}
      EMAIL_FROM: ${EMAIL_FROM}
      AWS_SES_SMTP_USER: ${AWS_SES_SMTP_USER}
      AWS_SES_SMTP_PASSWORD: ${AWS_SES_SMTP_PASSWORD}
      AWS_SES_REGION: ${AWS_SES_REGION}
      AWS_REGION: ${AWS_REGION}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      AWS_S3_REGION: ${AWS_S3_REGION}
      AWS_S3_ENDPOINT: ${AWS_S3_ENDPOINT}
      AWS_S3_FORCE_PATH_STYLE: ${AWS_S3_FORCE_PATH_STYLE}
      AWS_S3_PUBLIC_READ: ${AWS_S3_PUBLIC_READ}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      RBI_API_KEY: ${RBI_API_KEY}
      EXCHANGE_RATE_API_KEY: ${EXCHANGE_RATE_API_KEY}
      CRON_SECRET: ${CRON_SECRET}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - uploads:/app/uploads
      - invoices:/app/public/invoices
    networks:
      - taxhive-internal
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    # NO PORTS EXPOSED

  # Queue Worker - Internal only
  queue-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.production
      target: runner
    restart: unless-stopped
    command: npm run worker
    environment:
      # All configuration from .env file
      NODE_ENV: ${NODE_ENV}
      NEXTAUTH_URL: ${NEXTAUTH_URL}
      NEXTAUTH_SECRET: ${NEXTAUTH_SECRET}
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://default:${REDIS_PASSWORD}@redis:6379
      EMAIL_PROVIDER: ${EMAIL_PROVIDER}
      EMAIL_FROM: ${EMAIL_FROM}
      AWS_SES_SMTP_USER: ${AWS_SES_SMTP_USER}
      AWS_SES_SMTP_PASSWORD: ${AWS_SES_SMTP_PASSWORD}
      AWS_SES_REGION: ${AWS_SES_REGION}
      AWS_REGION: ${AWS_REGION}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      AWS_S3_REGION: ${AWS_S3_REGION}
      AWS_S3_ENDPOINT: ${AWS_S3_ENDPOINT}
      AWS_S3_FORCE_PATH_STYLE: ${AWS_S3_FORCE_PATH_STYLE}
      AWS_S3_PUBLIC_READ: ${AWS_S3_PUBLIC_READ}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      RBI_API_KEY: ${RBI_API_KEY}
      EXCHANGE_RATE_API_KEY: ${EXCHANGE_RATE_API_KEY}
      CRON_SECRET: ${CRON_SECRET}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - uploads:/app/uploads
      - invoices:/app/public/invoices
    networks:
      - taxhive-internal
    # Queue worker doesn't expose HTTP endpoints, so check if process is running
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -v grep | grep -q queue-worker || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Cloudflare Tunnel for secure external access
  cloudflared:
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    # Note: Since cloudflared is a distroless image without shell,
    # we need to handle the token differently. The token will be
    # injected during deployment.
    command: ["tunnel", "--no-autoupdate", "run"]
    environment:
      NODE_ENV: production
      # Token will be set via environment variable during deployment
    networks:
      - taxhive-internal
    depends_on:
      - app

networks:
  taxhive-internal:
    name: taxhive-${COMPOSE_ENV:-production}-network
    driver: bridge
    external: true

volumes:
  postgres_data:
  redis_data:
  uploads:
  invoices:

# MODIFICATION: Add top-level secrets block
# Secrets no longer needed - using .env file